# ğŸ¤– AI ChatBot with RAG

A powerful AI chatbot with Retrieval Augmented Generation (RAG) capabilities, featuring document ingestion and intelligent question-answering powered by Cerebras API.

## âœ¨ Features

- ğŸ“ **Document Upload**: Drag-and-drop support for PDF, TXT, and DOCX files
- ğŸ” **RAG Pipeline**: Intelligent document retrieval using ChromaDB vector store
- ğŸ’¬ **Streaming Chat**: Real-time responses from Cerebras LLM (ultra-fast inference)
- ğŸ“š **Source Citations**: Automatic citation of document sources in responses
- ğŸ¨ **Premium UI**: Modern glassmorphism design with dark mode
- âš¡ **Fast Processing**: Document chunking and embedding generation

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+ installed
- Cerebras API key (free tier available at [cerebras.ai](https://cerebras.ai))
- Optional: OpenAI API key for embeddings (can use Cerebras key as fallback)

### Installation

1. **Clone or navigate to the project directory**
   ```bash
   cd "c:\dev\AI ChatBot"
   ```

2. **Install dependencies** (already done if you followed setup)
   ```bash
   npm install
   ```

3. **Configure environment variables**
   
   Edit the `.env` file and add your API keys:
   ```env
   CEREBRAS_API_KEY=your_cerebras_api_key_here
   OPENAI_API_KEY=your_openai_api_key_here  # Optional, for embeddings
   PORT=3001
   UPLOAD_DIR=./uploads
   CHROMA_PATH=./chroma_db
   ```

### Running the Application

**Start both frontend and backend:**
```bash
npm run dev:all
```

This will start:
- Frontend (Vite): http://localhost:5173
- Backend (Express): http://localhost:3001

**Or run separately:**
```bash
# Terminal 1 - Frontend
npm run dev

# Terminal 2 - Backend
npm run server
```

## ğŸ“– Usage

1. **Upload Documents**
   - Navigate to the "Documents" tab
   - Drag and drop files or click to browse
   - Supported formats: PDF, TXT, DOCX (max 10MB)
   - Documents are automatically processed and indexed

2. **Chat with AI**
   - Switch to the "Chat" tab
   - Ask questions about your uploaded documents
   - The AI will retrieve relevant information and cite sources
   - Responses stream in real-time

## ğŸ—ï¸ Architecture

```
Frontend (React + Vite)
    â†“
Backend API (Express)
    â†“
â”œâ”€â”€ Document Processor (PDF/DOCX/TXT extraction)
â”œâ”€â”€ Vector Store (ChromaDB + OpenAI embeddings)
â””â”€â”€ LLM Client (Cerebras API)
```

### Tech Stack

- **Frontend**: React, Vite, CSS (Glassmorphism)
- **Backend**: Node.js, Express
- **Vector DB**: ChromaDB (local)
- **LLM**: Cerebras API (Llama 3.3 70B)
- **Embeddings**: OpenAI text-embedding-3-small
- **Document Processing**: pdf-parse, mammoth

## ğŸ“ Project Structure

```
AI ChatBot/
â”œâ”€â”€ src/                      # Frontend source
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ DocumentUpload.jsx
â”‚   â”‚   â”œâ”€â”€ DocumentUpload.css
â”‚   â”‚   â”œâ”€â”€ ChatInterface.jsx
â”‚   â”‚   â””â”€â”€ ChatInterface.css
â”‚   â”œâ”€â”€ App.jsx
â”‚   â””â”€â”€ index.css
â”œâ”€â”€ server/                   # Backend source
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ documents.js      # Upload/delete endpoints
â”‚   â”‚   â””â”€â”€ chat.js           # Chat endpoint
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ cerebrasClient.js # LLM integration
â”‚   â”‚   â”œâ”€â”€ vectorStore.js    # ChromaDB integration
â”‚   â”‚   â””â”€â”€ documentProcessor.js
â”‚   â””â”€â”€ index.js              # Express server
â”œâ”€â”€ uploads/                  # Uploaded documents
â”œâ”€â”€ chroma_db/               # Vector database
â”œâ”€â”€ .env                     # Environment variables
â””â”€â”€ package.json
```

## ğŸ”‘ API Endpoints

### Documents
- `POST /api/documents/upload` - Upload a document
- `GET /api/documents` - List all documents
- `DELETE /api/documents/:id` - Delete a document

### Chat
- `POST /api/chat` - Send a chat message (streaming response)

## ğŸ¨ UI Features

- **Glassmorphism Design**: Modern frosted glass effect
- **Dark Mode**: Eye-friendly dark theme
- **Smooth Animations**: Micro-interactions and transitions
- **Responsive Layout**: Works on desktop and mobile
- **Drag & Drop**: Intuitive file upload
- **Real-time Streaming**: See responses as they're generated

## ğŸ”§ Configuration

### Embedding Model
By default, the app uses OpenAI's `text-embedding-3-small` model. To use a different embedding provider, modify `server/services/vectorStore.js`.

### LLM Model
The app uses Cerebras' `llama-3.3-70b` model. To change models, edit `server/services/cerebrasClient.js`.

### Chunk Size
Document chunking is set to 1000 characters with 200 character overlap. Adjust in `server/services/documentProcessor.js`.

## ğŸ› Troubleshooting

**ChromaDB Connection Issues:**
- Ensure ChromaDB is properly installed: `npm install chromadb`
- Check that the `CHROMA_PATH` directory is writable

**API Key Errors:**
- Verify your Cerebras API key is correct in `.env`
- Check that the `.env` file is in the project root

**File Upload Fails:**
- Check file size (max 10MB)
- Ensure file format is supported (PDF, TXT, DOCX)
- Verify the `UPLOAD_DIR` exists and is writable

## ğŸ“ License

MIT License - feel free to use this project for your own purposes!

## ğŸ™ Acknowledgments

- Cerebras for ultra-fast LLM inference
- ChromaDB for vector storage
- OpenAI for embedding models
